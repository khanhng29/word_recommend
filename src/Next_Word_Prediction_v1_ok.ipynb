{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1Lz9tJkc1to8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./data2.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    data = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tách từ và loại bỏ ký tự đặc biệt\n",
        "\n",
        "def word_separation(input_data):\n",
        "    data = input_data.split('\\n')\n",
        "    token_underthesea = []\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in data:\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\sđĐáÁàÀảẢãÃạẠăĂắẮằẰẳẲẵẴạẠâÂấẤầẦẩẨẫẪậẬêÊếẾềỀểỂễỄệỆôÔốỐồỒổỔỗỖộỘơƠớỚờỜởỞỡỠợỢưƯứỨừỪửỬữỮựỰơƠáÁàÀảẢãÃạẠéÉèÈẻẺẽẼếẾềỀểỂễỄếẾêÊấẤầẦẩẨẫẪậẬíÍìÌỉỈĩĨịỊóÓòÒỏỎõÕọỌốỐồỒổỔỗỖộỘơƠớỚờỜởỞỡỠợỢúÚùÙủỦũŨụỤưỪỨừỪửỬữỮựỰýÝỳỲỷỶỹỸỵỴ\\s]+', '', sentence).lower()\n",
        "        sentences.append(text)\n",
        "\n",
        "        # Tách từ bằng Underthesea\n",
        "        tokens_underthesea = text.split(' ')\n",
        "        token_underthesea.append(tokens_underthesea)\n",
        "\n",
        "    return token_underthesea, sentences\n",
        "\n",
        "token_underthesea, train_input = word_separation(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b0Gw00vV88n5",
        "outputId": "f13602bf-e710-491b-f7f5-0fb26560dc22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['báo cáo tự đánh giá tđg là một phần của quá trình đảm bảo chất lượng đào tạo tại khoa x',\n",
              " 'báo cáo này bao gôm 03 phần chính',\n",
              " 'khái quát nhằm mô tả vắn tắt về báo cáo tđg quá trình tđg và giới thiệu vắn tắt về khoa x']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_input[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số từ trong câu: 258\n"
          ]
        }
      ],
      "source": [
        "# Tìm câu có số từ nhiều nhất\n",
        "\n",
        "word_counts = [len(sentence.split()) for sentence in train_input]\n",
        "\n",
        "max_word_count = max(word_counts)\n",
        "index_of_longest_sentence = word_counts.index(max_word_count)\n",
        "longest_sentence = train_input[index_of_longest_sentence]\n",
        "\n",
        "print(\"Số từ trong câu: {}\".format(max_word_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4CqnQFhS_z9",
        "outputId": "bfd789ed-5797-4e09-a5a9-a82106e1f9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'báo': 1, 'cáo': 2, 'tự': 3, 'đánh': 4, 'giá': 5, 'tđg': 6, 'là': 7, 'một': 8, 'phần': 9, 'của': 10, 'quá': 11, 'trình': 12, 'đảm': 13, 'bảo': 14, 'chất': 15, 'lượng': 16, 'đào': 17, 'tạo': 18, 'tại': 19, 'khoa': 20, 'x': 21, 'này': 22, 'bao': 23, 'gôm': 24, '03': 25, 'chính': 26, 'khái': 27, 'quát': 28, 'nhằm': 29, 'mô': 30, 'tả': 31, 'vắn': 32, 'tắt': 33, 'về': 34, 'và': 35, 'giới': 36, 'thiệu': 37, 'theo': 38, 'tiêu': 39, 'chuẩn': 40, 'chí': 41, 'đối': 42, 'với': 43, 'chương': 44, 'ngành': 45, 'bộ': 46, 'ctđt': 47, 'giáo': 48, 'dục': 49, 'ban': 50, 'hành': 51, 'thông': 52, 'tư': 53, '042016ttgdđt': 54, 'ngày': 55, '1432016': 56, 'kết': 57, 'luận': 58, 'tóm': 59, 'những': 60, 'điểm': 61, 'mạnh': 62, 'tồn': 63, 'vấn': 64, 'đề': 65, 'cần': 66, 'cải': 67, 'tiến': 68, 'kế': 69, 'hoạch': 70, 'tổng': 71, 'hợp': 72, 'quả': 73, 'cuối': 74, 'bản': 75, 'phụ': 76, 'lục': 77, 'gồm': 78, 'các': 79, 'tài': 80, 'liệu': 81, 'như': 82, 'quyết': 83, 'định': 84, 'thành': 85, 'lập': 86, 'hội': 87, 'đồng': 88, 'nhóm': 89, 'viết': 90, 'cơ': 91, 'sở': 92, 'dữ': 93, 'danh': 94, 'mục': 95, 'minh': 96, 'chứng': 97, 'đã': 98, 'nêu': 99, 'rõ': 100, 'cử': 101, 'nhân': 102, 'nguồn': 103, 'lực': 104, 'có': 105, 'khả': 106, 'năng': 107, 'phân': 108, 'tích': 109, 'thiết': 110, 'phát': 111, 'triển': 112, 'khai': 113, 'vận': 114, 'hệ': 115, 'thống': 116, 'tin': 117, 'để': 118, 'giải': 119, 'trong': 120, 'kinh': 121, 'tế': 122, 'quản': 123, 'lý': 124, 'trị': 125, 'doanh': 126, 'kĩ': 127, 'thái': 128, 'độ': 129, 'đáp': 130, 'ứng': 131, 'nhu': 132, 'cầu': 133, 'xã': 134, 'cao': 135, 'bối': 136, 'cảnh': 137, 'cách': 138, 'mạng': 139, 'công': 140, 'nghiệp': 141, '40': 142, 'đầu': 143, 'ra': 144, 'cđr': 145, 'đều': 146, 'được': 147, 'xác': 148, 'ràng': 149, 'yêu': 150, 'chung': 151, 'chuyên': 152, 'biệt': 153, 'thể': 154, 'hiện': 155, 'chi': 156, 'tiết': 157, 'ma': 158, 'trận': 159, 'môn': 160, 'học': 161, 'khối': 162, 'kiến': 163, 'thức': 164, 'đó': 165, 'yếu': 166, 'tố': 167, 'cụ': 168, 'hóa': 169, 'lĩnh': 170, 'vực': 171, 'kỹ': 172, 'cứng': 173, 'nghề': 174, 'nghiên': 175, 'cứu': 176, 'duy': 177, 'ngoại': 178, 'ngữ': 179, 'nắm': 180, 'vững': 181, 'sử': 182, 'dụng': 183, 'thạo': 184, 'mềm': 185, 'phẩm': 186, 'đạo': 187, 'đức': 188, 'cá': 189, 'thấy': 190, 'phù': 191, 'sứ': 192, 'mệnh': 193, 'tầm': 194, 'nhìn': 195, 'trường': 196, 'luật': 197, 'đại': 198, 'phản': 199, 'ánh': 200, 'bên': 201, 'liên': 202, 'quan': 203, '1': 204, 'cương': 205, 'bố': 206, 'trên': 207, 'website': 208, 'dễ': 209, 'dàng': 210, 'tiếp': 211, 'cận': 212, 'cũng': 213, 'cập': 214, 'triết': 215, 'gắn': 216, 'liền': 217, 'thực': 218, 'tiễn': 219, 'nhập': 220, 'quốc': 221, 'qua': 222, 'việc': 223, 'tăng': 224, 'cường': 225, 'xúc': 226, 'hoạt': 227, 'động': 228, 'tác': 229, 'đơn': 230, 'vị': 231, 'tập': 232, 'khóa': 233, 'mỗi': 234, 'đóng': 235, 'góp': 236, 'cho': 237, 'giúp': 238, 'sinh': 239, 'viên': 240, 'lũy': 241, 'hình': 242, 'tuyên': 243, 'vào': 244, 'chỉ': 245, '2': 246, 'xây': 247, 'dựng': 248, 'quy': 249, '': 250, 'gdđt': 251, 'thời': 252, 'người': 253, 'thị': 254, 'lao': 255, 'tổ': 256, 'chức': 257, 'ở': 258, 'khi': 259, 'từng': 260, 'hướng': 261, 'dẫn': 262, 'tốt': 263, 'dạy': 264, 'ctdh': 265, 'cấu': 266, 'trúc': 267, 'tỷ': 268, 'lệ': 269, 'tính': 270, 'cân': 271, 'giờ': 272, 'thuyết': 273, 'bổ': 274, '7': 275, 'đến': 276, '8': 277, 'kỳ': 278, 'tiên': 279, 'trước': 280, 'song': 281, 'logic': 282, 'tất': 283, 'cả': 284, 'khung': 285, 'không': 286, 'mà': 287, 'còn': 288, 'trí': 289, 'nhận': 290, 'sau': 291, 'trợ': 292, 'cạnh': 293, 'rộng': 294, 'sâu': 295, 'thêm': 296, 'khác': 297, 'hai': 298, 'bằng': 299, 'kép': 300, 'hoc': 301, 'lên': 302, 'bậc': 303, 'hơn': 304, '3': 305, 'dụcmục': 306, 'chiến': 307, 'lược': 308, 'lấy': 309, 'làm': 310, 'trung': 311, 'tâm': 312, 'giảng': 313, 'gv': 314, 'vai': 315, 'trò': 316, 'dắt': 317, 'truyền': 318, 'cảm': 319, 'hứng': 320, 'huy': 321, 'tinh': 322, 'thần': 323, 'chủ': 324, 'sáng': 325, 'luôn': 326, 'nỗ': 327, 'hết': 328, 'mình': 329, 'phương': 330, 'pháp': 331, 'cực': 332, 'ngừng': 333, 'nâng': 334, '4': 335, 'ngay': 336, 'từ': 337, 'mở': 338, 'tuyển': 339, 'k44': 340, 'năm': 341, '20082009': 342, 'áp': 343, 'kiểm': 344, 'tra': 345, 'ktđg': 346, 'nhất': 347, 'tượng': 348, 'chế': 349, 'tín': 350, 'ngân': 351, 'hàng': 352, 'thi': 353, 'rà': 354, 'soát': 355, 'hoàn': 356, 'thiện': 357, 'nhật': 358, 'nội': 359, 'dung': 360, 'phải': 361, 'cấp': 362, 'i': 363, 'tái': 364, 'biết': 365, 'hiểu': 366, 'iii': 367, 'iv': 368, 'bài': 369, 'gian': 370, 'tương': 371, 'số': 372, 'mật': 373, 'thikiểm': 374, 'nhiều': 375, 'đa': 376, 'dạng': 377, 'sự': 378, 'mức': 379, 'tham': 380, 'dự': 381, 'gia': 382, 'án': 383, 'giữa': 384, 'thúc': 385, 'viếttrắc': 386, 'nghiệm': 387, 'máy': 388, 'cậy': 389, 'nhà': 390, 'khoản': 391, 'hồi': 392, 'kịp': 393, '5': 394, 'đội': 395, 'ngũ': 396, 'thạc': 397, 'sỹ': 398, 'trở': 399, 'nckh': 400, 'hiệu': 401, 'nghệ': 402, '664': 403, 'đổisinh': 404, '1gv2056': 405, 'sv': 406, 'thấp': 407, 'viênsv': 408, '1gv25sv': 409, 'do': 410, '322015ttgdđt': 411, '16122015': 412, '6': 413, 'hỗ': 414, 'phục': 415, 'vụ': 416, 'bởi': 417, 'phòngbộ': 418, 'phận': 419, 'phòng': 420, 'thư': 421, 'viện': 422, 'chu': 423, 'khép': 424, 'kín': 425, 'đẩy': 426, 'khuyến': 427, 'khích': 428, 'nữa': 429, 'nhiệm': 430, 'giao': 431, 'đúng': 432, 'nước': 433, 'trườngkhoa': 434, 'đạt': 435, 'sách': 436, 'chăm': 437, 'sóc': 438, 'sức': 439, 'khỏe': 440, 'y': 441, 'đường': 442, 'điều': 443, 'kiện': 444, 'phong': 445, 'trào': 446, 'văn': 447, 'thao': 448, 'an': 449, 'toàn': 450, 'tôn': 451, 'trọng': 452, 'trương': 453, 'lối': 454, 'đảng': 455, 'chấp': 456, 'vật': 457, 'trạm': 458, 'ký': 459, 'túc': 460, 'xá': 461, 'chiếu': 462, 'wifi': 463, 'loa': 464, 'micro': 465, 'hòa': 466, 'nhiệt': 467, 'bị': 468, 'đèn': 469, 'quạt': 470, 'lắp': 471, 'đt': 472, 'đầy': 473, 'đủ': 474, 'ngoài': 475, 'thử': 476, 'bán': 477, 'kênh': 478, 'tối': 479, 'ưu': 480, 'tìm': 481, 'kiếm': 482, 'seo': 483, 'python': 484, 'photoshop': 485, '9': 486, 'đbcl': 487, 'chỉnh': 488, 'khảo': 489, 'uy': 490, 'đà': 491, 'nẵng': 492, 'phố': 493, 'hồ': 494, 'minhvà': 495, 'nền': 496, 'thế': 497, 'london': 498, 'anh': 499, 'bang': 500, 'washington': 501, 'mỹ': 502, 'ý': 503, 'cựu': 504, 'xem': 505, 'xét': 506, 'lại': 507, 'sung': 508, '10': 509, 'bền': 510, 'giám': 511, 'sát': 512, 'tình': 513, '11': 514, '50': 515, 'mt': 516, 'mã': 517, 'snabce': 518, 's': 519, 'hộp': 520, 'n': 521, 'thứ': 522, 'thì': 523, 'chuỗi': 524, '12': 525, 'a': 526, 'b': 527, 'c': 528, '01': 529, 'ví': 530, 'dụ': 531, 's11101': 532, 'mc': 533, 'thuộc': 534, 's33215': 535, '15': 536, '20212022': 537, 'đích': 538, 'trạng': 539, 'thách': 540, 'xuất': 541, 'tục': 542, 'bước': 543, 'đăng': 544, 'kđcl': 545, '568': 546, 'kh': 547, '25052021': 548, '2021': 549, '766qđ': 550, 'trách': 551, '30': 552, 'cán': 553, 'phòngtrung': 554, 'csvc': 555, 'thanh': 556, 'tratrung': 557, 'ctsv': 558, 'khu': 559, 'trú': 560, 'thí': 561, 'trưởng': 562, 'phó': 563, 'tịch': 564, 'trực': 565, '1074ktkđclgdgdđh': 566, 'gdđh': 567, '1075ktkđclgdgdđh': 568, 'cục': 569, '28062016': 570, 'thu': 571, 'thập': 572, 'xử': 573, 'đọc': 574, 'chéo': 575, 'tháng': 576, '102021': 577, 'họp': 578, 'phiên': 579, '112021': 580, 'trang': 581, 'rãi': 582, 'cùng': 583, 'phê': 584, 'duyệt': 585, 'sửa': 586, 'sẽ': 587, 'gửi': 588, 'thẩm': 589, 'đưa': 590, 'biện': 591, 'khắc': 592, 'giai': 593, 'đoạn': 594, 'tuy': 595, 'chưa': 596, 'nhưng': 597, 'trì': 598, '1960': 599, 'tiền': 600, 'thân': 601, 'thương': 602, 'ương': 603, '1965': 604, 'bắt': 605, '1979': 606, 'đổi': 607, 'tên': 608, '1994': 609, '2016': 610, 'mới': 611, '343': 612, 'thường': 613, 'kiệt': 614, 'phường': 615, 'lê': 616, 'hồng': 617, 'phủ': 618, 'tỉnh': 619, 'hà': 620, 'nam': 621, 'ăn': 622, 'tới': 623, 'đang': 624, '14': 625, '18': 626, 'đoàn': 627, 'niên': 628, 'binh': 629, 'nữ': 630, 'tri': 631, 'trụ': 632, '92021': 633, '740': 634, 'sư': 635, 'gs': 636, '49': 637, 'pgs': 638, '128': 639, 'ts': 640, '430': 641, 'ths': 642, '86': 643, '44': 644, 'thỉnh': 645, '16': 646, 'khách': 647, 'sạn': 648, 'dịch': 649, 'du': 650, 'lịch': 651, 'lữ': 652, 'marketing': 653, 'logistics': 654, 'cung': 655, 'toán': 656, 'ngôn': 657, '26': 658, '21': 659, 'trà': 660, 'đc': 661, 'thù': 662, '02': 663, '06': 664, '05': 665, '4000': 666, '4200': 667, '300': 668, '400': 669, 'vừa': 670, '500': 671, 'phạm': 672, 'vi': 673, 'nay': 674, 'rất': 675, 'thỏa': 676, 'thuận': 677, 'biên': 678, 'ghi': 679, 'nhớ': 680, 'lưới': 681, 'hoa': 682, 'canada': 683, 'đài': 684, 'loan': 685, 'hàn': 686, 'úc': 687, 'trao': 688, 'lưu': 689, 'thuật': 690, 'thảo': 691, 'hút': 692, 'bổng': 693, 'phối': 694, 'toulonvar': 695, 'marseille': 696, 'solbridge': 697, 'kwangwoon': 698, 'chungnam': 699, 'hùng': 700, 'quảng': 701, 'tây': 702, 'kwanseu': 703, 'gakuin': 704, 'cộng': 705, 'dân': 706, 'lào': 707, 'mông': 708, 'cổ': 709, 'trăm': 710, 'nghìn': 711, 'sĩ': 712, 'bồi': 713, 'dưỡng': 714, 'chục': 715, 'càng': 716, 'đất': 717, 'tng': 718, 'thưởng': 719, 'quý': 720, 'huân': 721, 'độc': 722, 'hạng': 723, 'ba': 724, '2000': 725, 'nhì': 726, '2008': 727, '2010': 728, '2014': 729, '2015': 730, 'cờ': 731, 'đua': 732, '2020': 733, '2005': 734, '28102016': 735, '876qđ': 736, 'sáp': 737, 'hữu': 738, '34': 739, '24': 740, 'phổ': 741, 'biến': 742, 'quán': 743, 'triệt': 744, 'sắc': 745, 'lãnh': 746, 'xu': 747, 'sản': 748, 'chuyển': 749, '2025': 750, '2030': 751, 'xếp': 752, 'đông': 753, 'á': 754, 'hiệp': 755, 'thừa': 756, 'nămlần': 757, 'lần': 758, 'gần': 759, '2019': 760, 'dựa': 761, 'florida': 762, 'ie': 763, 'nha': 764, 'louis': 765, 'phá': 766, 'đây': 767, 'việt': 768, 'huống': 769, 'mang': 770, 'lớn': 771, 'nối': 772, 'vên': 773, 'khởi': 774, 'lợi': 775, 'ty': 776, 'bravo': 777, 'ibpo': 778, 'sapo': 779, 'cybersoft': 780, 'tiềm': 781, 'trả': 782, 'lương': 783, 'trải': 784, 'căn': 785, 'cứ': 786, '022018': 787, 'nhược': 788, 'khẩn': 789, 'sao': 790, '2đã': 791, 'đòi': 792, 'hỏi': 793, '3hoàn': 794, '4thành': 795, 'câu': 796, 'lạc': 797, 'trau': 798, 'dồi': 799, 'xuyên': 800, '6đẩy': 801, 'k44s': 802, 'k57s': 803, 'mại': 804, 'cốt': 805, 'lõi': 806, 'nguyên': 807, 'tắc': 808, 'thiểu': 809, '072015ttgdđt': 810, '28112016': 811, '68qđ': 812, '10022017': 813, '112019': 814, '1566qđ': 815, '25122019': 816, '326': 817, '26042019': 818, 'tảng': 819, 'chú': 820, 'suốt': 821, 'đời': 822, '382005qh11': 823, '14062005': 824, 'diện': 825, 'khcn': 826, 'xứng': 827, 'thích': 828, 'nghi': 829, 'môi': 830, '082012qh13': 831, '2012': 832, 'nhiên': 833, '1982qđ': 834, 'ttg': 835, 'thủ': 836, 'tướng': 837, 'chắc': 838, 'phức': 839, 'tạp': 840, 'thay': 841, 'chịu': 842, 'bá': 843, '2040': 844, 'hoá': 845, 'tuệ': 846, 'bám': 847, 'asean': 848, 'vì': 849, 'vậy': 850, 'thác': 851, '12020': 852, 'địa': 853, 'bàn': 854, 'phía': 855, 'bắc': 856, 'sớm': 857, 'lầnnăm': 858, '2022': 859, 'so': 860, 'sánh': 861, '2017': 862, 'nghĩa': 863, 'mác': 864, 'lênin': 865, 'tưởng': 866, 'tiếng': 867, 'gdtc': 868, 'gdqp': 869, 'csdl': 870, 'kho': 871, 'am': 872, 'dùng': 873, 'cài': 874, 'trữ': 875, 'lựa': 876, 'chọn': 877, 'diễn': 878, 'soạn': 879, 'email': 880, 'mực': 881, 'rèn': 882, 'luyện': 883, 'vượt': 884, 'khó': 885, 'vươn': 886, 'nhau': 887, 'bình': 888, 'nói': 889, 'cht': 890, 'chẽ': 891, 'đắn': 892, 'kỷ': 893, 'erp': 894, 'bi': 895, 'web': 896, 'lỗ': 897, 'hổng': 898, 'cố': 899, 'nhanh': 900, 'lời': 901, 'cam': 902, 'khẳng': 903, 'cuộc': 904, 'thang': 905, 'đo': 906, '13': 907, 'loại': 908, '072015ttbộ': 909, '16042015': 910, 'họcvà': 911, '130': 912, 'bảng': 913, '46': 914, '367': 915, '396': 916, '389': 917, '41': 918, '35': 919, '39': 920, '359': 921, '406': 922, 'mẫu': 923, '42': 924, '1112020': 925, '17112020': 926, '27': 927, 'phiếu': 928, 'chiếm': 929, '90': 930, 'khá': 931, '407': 932, 'khoảng': 933, '433': 934, 'hầu': 935, 'đảo': 936, '411': 937, '441': 938, 'tiểu': 939, '062021': 940, 'lí': 941, 'kê': 942, 'điện': 943, 'tử': 944, 'sql': 945, 'server': 946, 'sang': 947, 'huấn': 948, 'team': 949, 'work': 950, 'chống': 951, 'tuý': 952, 'tệ': 953, 'nạn': 954, 'teamwork': 955, 'lớp': 956, 'tuyến': 957, 'rd': 958, 'uỷ': 959, 'quận': 960, 'huyện': 961, 'đẳng': 962, 'lường': 963, 'dn': 964, 'thăm': 965, 'dò': 966, 'đi': 967, 'buổi': 968, 'tọa': 969, 'đàm': 970, '67': 971, 'hoat': 972, 'đọng': 973, 'day': 974, 'phuong': 975, 'phap': 976, 'giang': 977, 'đuơc': 978, 'xay': 979, 'dưng': 980, 'dang': 981, 'phu': 982, 'hơp': 983, 'đê': 984, 'giup': 985, 'tiêp': 986, 'linh': 987, 'họi': 988, 'kiên': 989, 'thưc': 990, 'đat': 991, 'co': 992, 'thê': 993, 'tô': 994, 'chưc': 995, 'nhiêu': 996, 'khac': 997, 'nghe': 998, 'bày': 999, 'phép': 1000, 'chậm': 1001, 'tuỳ': 1002, '20192020': 1003, 'ảnh': 1004, 'hưởng': 1005, 'covid': 1006, 'trans': 1007, 'google': 1008, 'classroom': 1009, 'form': 1010, 'cac': 1011, 'ki': 1012, 'thuạt': 1013, 'hin': 1014, 'đai': 1015, 'hô': 1016, 'trơ': 1017, 'chiêu': 1018, 'video': 1019, 'tao': 1020, 'moi': 1021, 'truơng': 1022, 'ly': 1023, 'cuôn': 1024, 'hut': 1025, 'kêt': 1026, 'tôt': 1027, 'nhât': 1028, 'thoại': 1029, 'zalo': 1030, 'cvht': 1031, 'buộc': 1032, 'ấn': 1033, 'lộ': 1034, 'mong': 1035, 'muốn': 1036, 'nghien': 1037, 'cưu': 1038, 'đong': 1039, 'đao': 1040, 'tỉ': 1041, '80': 1042, 'hằng': 1043, 'nghị': 1044, 'chia': 1045, 'sẻ': 1046, 'gianh': 1047, 'thuơng': 1048, 'bctt': 1049, 'kltn': 1050, 'dài': 1051, 'tuần': 1052, 'nơi': 1053, 'biểu': 1054, 'khoá': 1055, 'ppctt': 1056, 'tuân': 1057, 'giấc': 1058, 'miễn': 1059, 'phí': 1060, 'giàu': 1061, 'điển': 1062, 'ipbo': 1063, 'tncs': 1064, 'sys': 1065, 'đan': 1066, 'xen': 1067, 'tấm': 1068, 'gương': 1069, 'trẻ': 1070, 'vien': 1071, 'tich': 1072, 'cưc': 1073, 'ngoai': 1074, 'đoan': 1075, 'nien': 1076, 'va': 1077, 'em': 1078, 'nguyn': 1079, 'hiên': 1080, 'mau': 1081, 'nhan': 1082, 'sưc': 1083, 'mua': 1084, 'giơ': 1085, 'trai': 1086, 'đât': 1087, 'bong': 1088, 'câp': 1089, 'bóng': 1090, 'ném': 1091, 'mùa': 1092, 'xuân': 1093, 'thiếu': 1094, 'is': 1095, 'got': 1096, 'talent': 1097, 'luy': 1098, 'lam': 1099, 'giau': 1100, 'them': 1101, 'ky': 1102, 'nang': 1103, 'thai': 1104, 'đọ': 1105, 'chuyen': 1106, 'nghip': 1107, 'tac': 1108, 'than': 1109, 'thin': 1110, 'trach': 1111, 'nhim': 1112, 'xa': 1113, 'toạ': 1114, 'xúctrao': 1115, 'đêu': 1116, 'thong': 1117, 'đanh': 1118, 'điêm': 1119, 'ren': 1120, 'luyn': 1121, 'vơi': 1122, 'thâp': 1123, 'cuọc': 1124, 'hop': 1125, 'xet': 1126, 'vu': 1127, 'phan': 1128, 'đên': 1129, 'điêu': 1130, 'chinh': 1131, 'cai': 1132, 'mọt': 1133, 'cach': 1134, 'kip': 1135, 'thơi': 1136, 'nguơi': 1137, 'long': 1138, 'hay': 1139, 'cua': 1140, 'đôi': 1141, 'quân': 1142, 'likert': 1143, '5rất': 1144, 'ýlà': 1145, '4đồng': 1146, 'ýtốt': 1147, '3khá': 1148, 'ýkhá': 1149, '2không': 1150, 'ýkém': 1151, '1hoàn': 1152, 'vạy': 1153, 'huơng': 1154, 'nhăm': 1155, 'chuân': 1156, 'đâu': 1157, 'mạnhcác': 1158, 'dưới': 1159, 'dù': 1160, 'nên': 1161, 'nghiêm': 1162, 'lưỡng': 1163, 'mối': 1164, '43': 1165, 'họ': 1166, '100': 1167, 'dạyhọc': 1168, 'thuần': 1169, 'thụ': 1170, 'nhồi': 1171, 'nhét': 1172, 'khơi': 1173, 'gợi': 1174, 'tòi': 1175, 'mọi': 1176, 'lúc': 1177, 'nhấn': 1178, 'cứutự': 1179, 'dành': 1180, 'coi': 1181, 'niềm': 1182, 'đam': 1183, 'mê': 1184, 'olympic': 1185, 'gp': 1186, 'gỡ': 1187, 'lắng': 1188, '435': 1189, '4265': 1190, 'riêng': 1191, 'đậm': 1192, 'dấu': 1193, 'mời': 1194, 'tải': 1195, '20062007': 1196, 'clo': 1197, 'khâu': 1198, 'thẳng': 1199, 'thpt': 1200, 'bloom': 1201, 'trắc': 1202, 'giấy': 1203, 'chấm': 1204, 'rubrics': 1205, 'con': 1206, '08': 1207, '104': 1208, 'quyền': 1209, 'nộp': 1210, 'hạn': 1211, 'qui': 1212, 'đợt': 1213, '95': 1214, 'ninh': 1215, 'luỹ': 1216, '200': 1217, 'bệnh': 1218, 'covid19': 1219, 'vẫn': 1220, '52': 1221, 'slide': 1222, 'chữ': 1223, 'ôn': 1224, 'kì': 1225, 'pktđbclgdsau': 1226, 'túi': 1227, 'xong': 1228, 'kèm': 1229, '07': 1230, 'cổng': 1231, 'tbc': 1232, 'kltt': 1233, 'khiếu': 1234, 'nại': 1235, 'kiếu': 1236, 'vòng': 1237, 'kể': 1238, 'pqlđt': 1239, 'nếu': 1240, 'rơi': 1241, 'khen': 1242, 'phấn': 1243, 'đấu': 1244, '20202021': 1245, '224': 1246, '492': 1247, 'giảm': 1248, 'in': 1249, 'đĩa': 1250, 'đĩa01': 1251, 'chiết': 1252, 'rubric': 1253, 'bạch': 1254, 'nhỏ': 1255, 'đỡ': 1256, '55': 1257, 'lễ': 1258, 'cẩm': 1259, 'phúc': 1260, 'thắc': 1261, 'mắc': 1262, 'hòm': 1263, 'nguyện': 1264, 'vọng': 1265, 'ít': 1266, 'phàn': 1267, 'nàn': 1268, 'sai': 1269, 'sót': 1270, 'nhầm': 1271, 'lẫn': 1272, 'kt': 1273, 'đbclgd': 1274, 'viênphụ': 1275, 'huynh': 1276, 'đáng': 1277, 'cũ': 1278, 'dõi': 1279, 'dần': 1280, '20162021': 1281, 'hài': 1282, 'lòng': 1283, '362': 1284, '2018': 1285, 'chóng': 1286, 'tiện': 1287, '1982qđtt': 1288, '1021tb': 1289, 'gọi': 1290, 'a00': 1291, 'a01': 1292, 'd01': 1293, 'd07': 1294, 'gián': 1295, 'd': 1296, 'f': 1297, 'kéo': 1298, 'tùy': 1299, 'ích': 1300, 'nổi': 1301, 'trội': 1302, 'module': 1303, 'nào': 1304, 'xin': 1305, 'plos': 1306, '432007qđbgdđt': 1307, 'chỉvà': 1308, 'lọc': 1309, 'cbgd': 1310, 'kiêm': 1311, 'cb': 1312, 'tc': 1313, '36': 1314, 'hànhthảo': 1315, '20': 1316, 'sungđiều': 1317, 'chỉnhcập': 1318, 'clos': 1319, 'nhómđược': 1320, 'phú': 1321, 'mốc': 1322, 'tờ': 1323, 'tân': 1324, 'viêncũng': 1325, 'họcđể': 1326, 'sắp': 1327, 'phầntại': 1328, 'httpsxeduvn': 1329, 'httpsxtmdtxeduvn': 1330, 'nhờ': 1331, 'rệt': 1332, '854': 1333, '3744': 1334, 'thật': 1335, 'thói': 1336, 'quen': 1337, 'truy': 1338, 'then': 1339, 'chốt': 1340, 'trật': 1341, 'dẫnquy': 1342, '768tb': 1343, '15112016': 1344, '952tb': 1345, '29122016': 1346, '326tb': 1347, '2642019': 1348, '17092021': 1349, 'nằm': 1350, '131': 1351, '29': 1352, '221': 1353, '28': 1354, '214': 1355, '313': 1356, '92': 1357, '76': 1358, '84': 1359, 'plo1': 1360, 'plo2': 1361, 'plo3': 1362, 'plo6': 1363, 'plo10': 1364, 'plo11': 1365, 'plo12': 1366, 'plo13': 1367, 'plo14': 1368, 'plo16': 1369, 'plo17': 1370, 'plo8': 1371, 'plo9': 1372, 'plo15': 1373, 'đươc': 1374, 'khía': 1375, 'đắc': 1376, 'plo4': 1377, 'plo5': 1378, 'plo7': 1379, 'plo18': 1380, 'buộctự': 1381, 'chungcơ': 1382, 'sởchuyên': 1383, 'ngànhtiên': 1384, 'lượt': 1385, 'kỳbài': 1386, 'vệ': 1387, 'niệm': 1388, 'đám': 1389, 'phán': 1390, '60': 1391, 'internet': 1392, 'khám': 1393, 'xmột': 1394, '73': 1395, '27022017': 1396, '1134': 1397, 'clo1': 1398, 'clo2': 1399, 'clo3': 1400, 'clo4': 1401, 'clo5': 1402, 'vàng': 1403, '31': 1404, '32': 1405, 'viii': 1406, 's22204': 1407, 'trưng': 1408, 'vài': 1409, 'ii': 1410, 'v': 1411, 'cuốn': 1412, 'rút': 1413, 'ngắn': 1414, 'mạch': 1415, '120': 1416, '144': 1417, '133': 1418, '138': 1419, '127': 1420, 'đinh': 1421, 'vii': 1422, 'ix': 1423, 'đợi': 1424, 'họcngười': 1425, '2tc': 1426, '25': 1427, 'bớt': 1428, 'xuống': 1429, 'lẽ': 1430, '116': 1431, '91': 1432, 'xkt': 1433, 'châm': 1434, 'gắng': 1435, '286bqđ': 1436, '2952013': 1437, '1468': 1438, 'tận': 1439, '768': 1440, '952': 1441, 'mẽ': 1442, '2011': 1443, 'clip': 1444, 'chúng': 1445, 'isiscopus': 1446, 'đoạt': 1447, 'thấu': 1448, 'cư': 1449, 'nganh': 1450, 'hinh': 1451, 'tưng': 1452, 'sổ': 1453, '395': 1454, 'điền': 1455, '397': 1456, '422': 1457, '437': 1458, '154': 1459, '103134': 1460, '374': 1461, '89109': 1462, '398': 1463, '121150': 1464, '51': 1465, '0': 1466, 'sơ': 1467, 'bốc': 1468, 'trùng': 1469, '523502': 1470, '148': 1471, '20182019': 1472, '714757': 1473, 'phầnbài': 1474, '489': 1475, '25052020': 1476, 'bô': 1477, 'nghỉ': 1478, 'tránh': 1479, 'đu': 1480, 'lân': 1481, '19': 1482, 'gvcc': 1483, '119': 1484, 'gvc': 1485, '842': 1486, '1619': 1487, '105': 1488, '219': 1489, '1419gv': 1490, '736': 1491, '2036': 1492, '09': 1493, '62': 1494, 'hưu': 1495, 'tuổi': 1496, 'ncs': 1497, '900': 1498, '1820': 1499, '220': 1500, 'sẵn': 1501, 'sàng': 1502, 'namnữ': 1503, 'nguy': 1504, 'hẫng': 1505, 'hụt': 1506, 'hàm': 1507, 'ngạch': 1508, 'viênngười': 1509, '82016': 1510, '38': 1511, '0320': 1512, '150': 1513, '1520': 1514, '750': 1515, '720': 1516, 'qđ': 1517, '1023qđ': 1518, '20082018': 1519, '270': 1520, '45': 1521, 'phúttiết': 1522, '700': 1523, '650': 1524, '600': 1525, 'khtc': 1526, 'cái': 1527, '768qđ': 1528, '31102017': 1529, 'huyết': 1530, 'lâu': 1531, 'ngànhchuyên': 1532, 'trúng': 1533, 'ielts65': 1534, 'toefl': 1535, 'ibt': 1536, 'canh': 1537, 'chiều': 1538, 'gspgs': 1539, 'dạn': 1540, 'khăn': 1541, 'ptcns': 1542, 'cấm': 1543, '923qđ': 1544, '1682019': 1545, '210qđ': 1546, '2352011': 1547, '250': 1548, '520': 1549, '1920': 1550, '950': 1551, '2020100': 1552, '613': 1553, 'ủy': 1554, 'isi': 1555, 'scopus': 1556, '614': 1557, '615': 1558, '580qđ': 1559, '1038qđ': 1560, 'góc': 1561, 'bổi': 1562, '109qđ': 1563, '0832017': 1564, 'seminar': 1565, '1853qđ': 1566, '28122018': 1567, 'cn': 1568, 'trườngviện': 1569, '426': 1570, '619': 1571, '04': 1572, 'soạnbổ': 1573, 'báobài': 1574, 'đồ': 1575, '61': 1576, 'sống': 1577, '620': 1578, '621': 1579, '291qđ': 1580, '739qđ': 1581, 'rồi': 1582, 'giữ': 1583, '417': 1584, 'tcns': 1585, '14122020': 1586, 'bó': 1587, 'vô': 1588, '486qđ': 1589, '852019': 1590, 'quyền\\t': 1591, 'hộ': 1592, 'giả': 1593, 'qlkh': 1594, '2082018': 1595, '622': 1596, 'đổigiờ': 1597, '623': 1598, 'thầu': 1599, '624': 1600, '625': 1601, '20172018': 1602, '626': 1603, 'đương': 1604, 'issn': 1605, 'lái': 1606, 'xe': 1607, 'chât': 1608, 'luơng': 1609, 'lơn': 1610, 'thuọc': 1611, 'h': 1612, 'tuong': 1613, 'giưa': 1614, 'đọi': 1615, 'ngu': 1616, 'dich': 1617, 'khao': 1618, 'mưc': 1619, 'khăc': 1620, 'phuc': 1621, 'triên': 1622, 'hiu': 1623, 'hon': 1624, 'lưa': 1625, 'chon': 1626, 'chiên': 1627, 'luơc': 1628, '17238': 1629, '714': 1630, '123238': 1631, '5168': 1632, '69238': 1633, '2899': 1634, '29238': 1635, '1218': 1636, '71': 1637, '5882': 1638, 'quỹ': 1639, '20212030': 1640, 'ổn': 1641, 'vụgiảng': 1642, '20212025': 1643, '65': 1644, '17': 1645, 'vụgv': 1646, '20262030': 1647, '70': 1648, '035': 1649, 'vê': 1650, 'vic': 1651, 'hoach': 1652, 'vin': 1653, 'ngh': 1654, 'ưng': 1655, 'cọng': 1656, 'ơ': 1657, 'van': 1658, 'quyêt': 1659, 'vân': 1660, 'bông': 1661, 'ngưng': 1662, 'thôi': 1663, 'giây': 1664, 'chưng': 1665, 'nhạn': 1666, 'thăc': 1667, 'măc': 1668, 'băng': 1669, 'đuong': 1670, 'khôi': 1671, 'đăc': 1672, 'lưc': 1673, 'tai': 1674, 'thwucj': 1675, 'sô': 1676, 'tu': 1677, 'liu': 1678, 'cạp': 1679, 'nhạt': 1680, 'loai': 1681, 'kin': 1682, 'thuạn': 1683, 'lơi': 1684, 'thoả': 1685, 'mãn': 1686, 'thiêt': 1687, 'vạt': 1688, 'cô': 1689, 'lơp': 1690, 'tre': 1691, 'vưng': 1692, 'kha': 1693, '1095': 1694, 'dư': 1695, 'phai': 1696, '22': 1697, 'luạt': 1698, 'khoẻ': 1699, 'trái': 1700, '292012nđcp': 1701, 'phâm': 1702, 'nghê': 1703, 'cu': 1704, 'truong': 1705, 'đuơng': 1706, 'lôi': 1707, 'nuơc': 1708, 'hiêu': 1709, 'biêt': 1710, 'hoạc': 1711, 'vưc': 1712, 'đưc': 1713, 'lich': 1714, 'quyên': 1715, 'bọ': 1716, 'ngư': 1717, 'b2': 1718, 'vuơt': 1719, 'tât': 1720, 'ca': 1721, 'httpwwwxeduvn': 1722, 'niêm': 1723, 'yêt': 1724, 'bât': 1725, 'se': 1726, 'ngach': 1727, 'thưa': 1728, 'bôi': 1729, 'duơng': 1730, '789qđ': 1731, 'miên': 1732, 'phô': 1733, '449': 1734, 'khoaphòng': 1735, '4245': 1736, '4285': 1737, 'phôi': 1738, 'đon': 1739, 'tuc': 1740, 'z': 1741, 'bgh': 1742, '2692016': 1743, 'bẳng': 1744, '8797': 1745, '705': 1746, '5228': 1747, 'viêngiảng': 1748, 'ủng': 1749, 'ững': 1750, 'thuê': 1751, '74': 1752, '238': 1753, '878': 1754, '167': 1755, '96': 1756, '7793000000đ': 1757, '75': 1758, 'trích': 1759, 'vướng': 1760, 'bật': 1761, 'khiêm': 1762, 'tốn': 1763, 'thâm': 1764, 'tạm': 1765, 'ước': 1766, 'cbql': 1767, '72': 1768, 'phủtheo': 1769, '57': 1770, 'ngưỡng': 1771, 'httpthituyensinhvn': 1772, 'httpsnghiepvuthituyensinhvn': 1773, 'httpxeduvn': 1774, 'facebook': 1775, 'hải': 1776, 'mãi': 1777, 'bách': 1778, 'ngôi': 1779, '81': 1780, 'nv1': 1781, 'tranh': 1782, 'tỏ': 1783, 'top': 1784, '2630': 1785, '2654': 1786, 'đứng': 1787, '173': 1788, '171': 1789, '263': 1790, '274': 1791, 'chênh': 1792, '145': 1793, 'chỗ': 1794, 'tiệm': 1795, 'gây': 1796, '82': 1797, 'thimôn': 1798, 'giỏi': 1799, 'giản': 1800, 'khắt': 1801, 'khe': 1802, 'hứa': 1803, 'hn': 1804, '012014ttgdđt': 1805, '2412014': 1806, '979qđ': 1807, 'hạ': 1808, 'gx': 1809, 'ảo': 1810, 'bỏ': 1811, 'lệch': 1812, 'bcn': 1813, 'nghiệpdn': 1814, '9015': 1815, 'triệu': 1816, 'đồngtháng': 1817, 'thăng': 1818, '83': 1819, 'thiều': 1820, '85': 1821, 'hòng': 1822, 'kém': 1823, 'chấn': 1824, 'hp': 1825, 'hè': 1826, 'hẳn': 1827, 'thậm': 1828, 'k52': 1829, 'trừ': 1830, 'qlđt': 1831, 'lành': 1832, 'đón': 1833, 'đhcq': 1834, 'dừng': 1835, 'spss': 1836, 'hiến': 1837, 'máu': 1838, 'đá': 1839, 'cv': 1840, 'phỏng': 1841, 'vay': 1842, 'vốn': 1843, 'ti': 1844, 'tậpbảng': 1845, 'sân': 1846, 'chơi': 1847, 'eplus': 1848, 'vis': 1849, 'hát': 1850, 'nhảy': 1851, 'vũ': 1852, 'nhịp': 1853, 'điệu': 1854, 'xanh': 1855, 'lông': 1856, 'đh': 1857, '87': 1858, '9120': 1859, '9670': 1860, '9700': 1861, 'clb': 1862, 'thoải': 1863, 'mái': 1864, 'nề': 1865, 'nếp': 1866, 'kỉ': 1867, 'đình': 1868, 'phóng': 1869, 'h1': 1870, 'cự': 1871, 'chào': 1872, 'xs': 1873, 'bộc': 1874, 'iss': 1875, 'rổ': 1876, 'thú': 1877, 'mis': 1878, 'and': 1879, 'more': 1880, 'workshop': 1881, 'xktx': 1882, 'hấp': 1883, 'bạn': 1884, 'atm': 1885, '20162017': 1886, 'cửa': 1887, 'trưa': 1888, 'ngơi': 1889, 'bãi': 1890, 't': 1891, 'cd': 1892, 'tầng': 1893, 'ghế': 1894, 'âm': 1895, 'h2': 1896, 'h3': 1897, 'ngồi': 1898, 'tường': 1899, 'sạch': 1900, 'khang': 1901, 'uống': 1902, '21m2': 1903, '800900': 1904, '1000': 1905, 'trọ': 1906, 'ktx': 1907, '142014ttbyt': 1908, '0652013': 1909, '20172021': 1910, 'hiểm': 1911, 'test': 1912, 'heroin': 1913, 'phun': 1914, 'thuốc': 1915, 'căng': 1916, 'khuôn': 1917, 'cây': 1918, 'đp': 1919, 'thoáng': 1920, 'mát': 1921, 'tràn': 1922, 'ngập': 1923, '301': 1924, '40m2': 1925, '25m2': 1926, '82018': 1927, 'xung': 1928, 'quanh': 1929, '79': 1930, 'tùng': 1931, 'mậu': 1932, 'tủ': 1933, 'g': 1934, 'sàn': 1935, '32231m2': 1936, 'chứa': 1937, 'máyphòng': 1938, 'dây': 1939, 'suất': 1940, 'màn': 1941, 'chờ': 1942, 'tòa': 1943, 'móc': 1944, 'hư': 1945, 'hỏng': 1946, 'chữa': 1947, 'sắm': 1948, 'cbvc': 1949, 'thấycsvc': 1950, 'ccác': 1951, '2600m2': 1952, '102018': 1953, 'p': 1954, 'mượn': 1955, 'svsinh': 1956, 'scan': 1957, 'ilib': 1958, '2002': 1959, '2003': 1960, 'dlib': 1961, 'sưu': 1962, 'sóng': 1963, '800': 1964, '160': 1965, '72021': 1966, '36668': 1967, '139865': 1968, '1570': 1969, 'rom': 1970, 'ebook': 1971, 'nxb': 1972, 'igroup': 1973, 'proquets': 1974, 'central': 1975, '553': 1976, '24413': 1977, '264': 1978, '11996': 1979, 'std': 1980, '1987': 1981, 'kqnc': 1982, 'llà': 1983, 'vềể': 1984, '11000': 1985, 'proquest': 1986, '19000': 1987, '13000': 1988, 'credo': 1989, 'referencel': 1990, 'reference': 1991, '200000': 1992, 'tệp': 1993, '40000': 1994, '90000': 1995, 'fulbright': 1996, '241278': 1997, '311140': 1998, '9169': 1999, '1834': 2000, 'lượtnăm': 2001, '15785': 2002, '3157': 2003, '2299': 2004, '460': 2005, '3801': 2006, '760': 2007, 'dụngnsd': 2008, '763': 2009, '765': 2010, '480': 2011, '6000': 2012, 'm2': 2013, 'tốc': 2014, 'củathư': 2015, 'opac': 2016, 'xảy': 2017, 'lỗi': 2018, '93': 2019, '54': 2020, 'm2phòng': 2021, 'tínhphòng': 2022, 'viênphòngca': 2023, 'chồng': 2024, 'tần': 2025, 'di': 2026, '432': 2027, '427': 2028, 'ồn': 2029, 'mưu': 2030, 'gỗ': 2031, 'kính': 2032, '94': 2033, 'phôtô': 2034, 'firewall': 2035, 'chạy': 2036, '197': 2037, 'máy1': 2038, 'tay': 2039, 'leased': 2040, 'line': 2041, '70mb': 2042, '300mb': 2043, 'xách': 2044, 'fanpage': 2045, 'giãn': 2046, 'online': 2047, '15000': 2048, 'msteams': 2049, 'meeting': 2050, '\\t': 2051, 'đem': 2052, '2023': 2053, 'khuyết': 2054, 'tật': 2055, 'ccvccông': 2056, 'chứcccvc': 2057, 'bục': 2058, 'ấm': 2059, 'itc': 2060, 'dọn': 2061, 'dãy': 2062, 'nóng': 2063, 'lạnh': 2064, 'lang': 2065, 'lau': 2066, 'cống': 2067, 'thoát': 2068, 'ứ': 2069, 'thùng': 2070, 'rác': 2071, 'nắp': 2072, 'đậy': 2073, 'diệt': 2074, 'muỗi': 2075, 'côn': 2076, 'sốt': 2077, 'thải': 2078, 'sảnh': 2079, 'vsattp': 2080, 'oresol': 2081, 'biseptol': 2082, 'paracetamol': 2083, 'cloraminb': 2084, 'nacl': 2085, 'đột': 2086, 'tiêm': 2087, 'cbgv': 2088, '5k': 2089, 'cbnv': 2090, 'mũi': 2091, 'bác': 2092, 'ttrường': 2093, 'byt': 2094, 'k51': 2095, '2424': 2096, 'ngừa': 2097, 'cắt': 2098, 'làn': 2099, 'vứt': 2100, 'bừa': 2101, 'hái': 2102, 'bẻ': 2103, 'cành': 2104, 'tuyệt': 2105, 'cháy': 2106, 'pccc': 2107, 'ccũng': 2108, 'cháypccc': 2109, 'pcccphòng': 2110, 'khií': 2111, 'xẩy': 2112, 'nổ': 2113, 'trù': 2114, 'ccvc': 2115, 'cởi': 2116, 'chô': 2117, 'din': 2118, 'khoe': 2119, 'nọi': 2120, 'duc': 2121, 'nguôn': 2122, 'quôc': 2123, 'tê': 2124, 'găn': 2125, 'chuong': 2126, 'chê': 2127, 'hôi': 2128, '101': 2129, '172021ttbgdđt': 2130, '1699qđ': 2131, '1041tb': 2132, 'ctđtctdh': 2133, '53': 2134, '25212019': 2135, 'lồng': 2136, 'ghép': 2137, 'đựng': 2138, '102': 2139, 'nét': 2140, 'dọc': 2141, 'ngang': 2142, 'báu': 2143, 'trắng': 2144, 'khđt': 2145, 'ktđbclgd': 2146, 'đàạo': 2147, '103': 2148, 'mấu': 2149, 'luân': 2150, 'đn': 2151, 'năm1': 2152, 'kẽ': 2153, 'doc': 2154, 'hủy': 2155, 'ngẫu': 2156, '257': 2157, 'download': 2158, 'quyển': 2159, 'họa': 2160, 'rằng': 2161, '20162020': 2162, 'hào': 2163, 'độngdịch': 2164, 'sữa': 2165, 'trần': 2166, 'kí': 2167, 'nsd': 2168, 'khát': 2169, 'bếp': 2170, 'can': 2171, 'thiệp': 2172, 'nhắc': 2173, 'nhở': 2174, 'đôn': 2175, 'đốc': 2176, 'khắn': 2177, 'ccông': 2178, '106': 2179, '615tmtcttr': 2180, '23': 2181, '2007': 2182, 'clđt': 2183, 'gvnhà': 2184, 'dụngsinh': 2185, 'họcgvnhà': 2186, 'chọntheo': 2187, 'word': 2188, 'docs': 2189, 'link': 2190, 'excel': 2191, 'file': 2192, 'sheet': 2193, 'tctín': 2194, 'tứ': 2195, 'thầycô': 2196, 'thầy': 2197, 'phốisự': 2198, 'banbộ': 2199, 'hhoạt': 2200, 'hợpsự': 2201, '111': 2202, 'lùi': 2203, 'khẩu': 2204, '113': 2205, 'nợ': 2206, 'bạc': 2207, '112': 2208, '2006': 2209, 'nghệp': 2210, 'k54': 2211, '123': 2212, '115': 2213, 'hề': 2214, 'nhữưng': 2215, 'cmndcccd': 2216, '9116': 2217, '9701': 2218, 'tựu': 2219, 'svtn': 2220, 'nó': 2221, 'nghiệpsvtn': 2222, 'wwebsite': 2223, 'đàn': 2224, 'lai': 2225, '114': 2226, 'gấp': 2227, '1111': 2228, '1112': 2229, 'quan\\t': 2230, 'pktđbclgd': 2231, 'googledoc': 2232, 'ktđbcl': 2233, '3836': 2234, '4371': 2235, '4225': 2236, '4202': 2237, 'năngnăng': 2238, '3967': 2239, '4343': 2240, '4324': 2241, '4258': 2242, '4338': 2243, 'nlđ': 2244, 'nn': 2245, 'tkđg': 2246, 'xhiện': 2247, '012020': 2248, 'zalovới': 2249, 'gd': 2250, 'ccđt': 2251, '20222023': 2252, 'vẽ': 2253, '00': 2254, 'ô': 2255, 'cột': 2256, 'tskh': 2257, 'xátổng': 2258, '3cột': 2259, 'nhánh': 2260, '1020': 2261, '050': 2262, '83700': 2263, '14139': 2264, 'vui': 2265, '6058': 2266, '29617': 2267, '277': 2268, 'm21': 2269, '12417': 2270, 'vpk': 2271, 'bm': 2272, '360': 2273, '0025': 2274, '770': 2275, '644': 2276, '64422': 2277, '2927': 2278, '9017': 2279, '892': 2280, '108': 2281, '973': 2282, 'quântháng': 2283, 'vnđ': 2284, '852': 2285, '7020': 2286, '5620': 2287, '280': 2288, '697520': 2289, '349': 2290, '047': 2291, '2122': 2292, '9545': 2293, '521': 2294, '1621': 2295, '7619': 2296, '5065': 2297, '1021': 2298, '048': 2299, '7021': 2300, '033': 2301, '5621': 2302, '267': 2303, '697521': 2304, '33': 2305}\n",
            "Số lượng từ trong bộ từ điển: 2305\n"
          ]
        }
      ],
      "source": [
        "# Xây dựng bộ từ điển từ danh sách token\n",
        "\n",
        "def build_vocab(token_underthesea):\n",
        "    vocab = {}\n",
        "    for token in token_underthesea:\n",
        "        for word in token:\n",
        "            if word not in vocab:\n",
        "                vocab[word] = len(vocab) + 1\n",
        "    return vocab\n",
        "\n",
        "\n",
        "vocab = build_vocab(token_underthesea)\n",
        "print(vocab)\n",
        "print(\"Số lượng từ trong bộ từ điển:\", len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chuẩn bị dữ liệu đầu vào cho mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QB-NjH8SQ3TJ"
      },
      "outputs": [],
      "source": [
        "# Tạo batch size và dataset\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(train_input)\n",
        "\n",
        "batch_size = 32\n",
        "batched_dataset = dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "en0i56cUFO8a"
      },
      "outputs": [],
      "source": [
        "# Vector hóa dữ liệu bằng TextVectorization layer\n",
        "\n",
        "sequence_length = max_word_count            # Số lượng từ tối đa trong 1 câu\n",
        "vocab_size = 50                           # Lớp TextVectorization chỉ xét 10 từ thường gặp nhất.\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens = vocab_size,\n",
        "    output_mode = \"int\",\n",
        "    output_sequence_length = sequence_length,\n",
        ")\n",
        "text_vectorization.adapt(batched_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4YRs4_7rGj9W"
      },
      "outputs": [],
      "source": [
        "def prepare_lm_dataset(text_batch):\n",
        "    vectorized_sequences = text_vectorization(text_batch)\n",
        "    x = vectorized_sequences[:, :-1]\n",
        "    y = vectorized_sequences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "lm_dataset = batched_dataset.map(prepare_lm_dataset, num_parallel_calls = 4)    # num_parallel_calls cho phép train song song trên nhiều phần tử"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tDQSlS3bo63P"
      },
      "outputs": [],
      "source": [
        "# Chia dữ liệu\n",
        "\n",
        "val_size = 0.3\n",
        "val_steps = int(val_size * lm_dataset.cardinality().numpy())\n",
        "train_steps = lm_dataset.cardinality().numpy() - val_steps\n",
        "\n",
        "val_dataset = lm_dataset.take(val_steps)\n",
        "train_dataset = lm_dataset.skip(val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmuaxnjhqEjF",
        "outputId": "659b5b39-7abc-4608-d975-a54d9de41531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=(TensorSpec(shape=(None, 257), dtype=tf.int64, name=None), TensorSpec(shape=(None, 257), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Khởi tạo model transformer và seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fzy2jhyBG_iF"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dropout(0.2),\n",
        "             layers.Dense(embed_dim)]\n",
        "        )\n",
        "\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TransformerDecoder, self).get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TuU6Y2UeHWNE"
      },
      "outputs": [],
      "source": [
        "# Tạo mô hình\n",
        "\n",
        "embed_dim = 256\n",
        "latent_dim = 1024\n",
        "num_heads = 2\n",
        "\n",
        "# Đầu vào là 1 tenxo có dạng (batch_size, sequence_length)\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
        "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pWld4z7nasr",
        "outputId": "25a4afb9-a995-44cb-eaa5-20f6e091a328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.9130 - accuracy: 0.6195\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56533, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 131s 1s/step - loss: 1.9130 - accuracy: 0.6195 - val_loss: 1.9553 - val_accuracy: 0.5653\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ductr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104/104 [==============================] - ETA: 0s - loss: 1.7770 - accuracy: 0.6305\n",
            "Epoch 2: val_accuracy improved from 0.56533 to 0.62068, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 132s 1s/step - loss: 1.7770 - accuracy: 0.6305 - val_loss: 1.7774 - val_accuracy: 0.6207\n",
            "Epoch 3/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.7308 - accuracy: 0.6348\n",
            "Epoch 3: val_accuracy improved from 0.62068 to 0.63851, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 130s 1s/step - loss: 1.7308 - accuracy: 0.6348 - val_loss: 1.7094 - val_accuracy: 0.6385\n",
            "Epoch 4/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.6974 - accuracy: 0.6371\n",
            "Epoch 4: val_accuracy did not improve from 0.63851\n",
            "104/104 [==============================] - 136s 1s/step - loss: 1.6974 - accuracy: 0.6371 - val_loss: 1.6940 - val_accuracy: 0.6342\n",
            "Epoch 5/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.6706 - accuracy: 0.6397\n",
            "Epoch 5: val_accuracy improved from 0.63851 to 0.63995, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 138s 1s/step - loss: 1.6706 - accuracy: 0.6397 - val_loss: 1.6502 - val_accuracy: 0.6399\n",
            "Epoch 6/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.6396 - accuracy: 0.6424\n",
            "Epoch 6: val_accuracy improved from 0.63995 to 0.64196, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 140s 1s/step - loss: 1.6396 - accuracy: 0.6424 - val_loss: 1.6288 - val_accuracy: 0.6420\n",
            "Epoch 7/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.6119 - accuracy: 0.6451\n",
            "Epoch 7: val_accuracy did not improve from 0.64196\n",
            "104/104 [==============================] - 141s 1s/step - loss: 1.6119 - accuracy: 0.6451 - val_loss: 1.6063 - val_accuracy: 0.6277\n",
            "Epoch 8/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.5855 - accuracy: 0.6474\n",
            "Epoch 8: val_accuracy did not improve from 0.64196\n",
            "104/104 [==============================] - 135s 1s/step - loss: 1.5855 - accuracy: 0.6474 - val_loss: 1.5846 - val_accuracy: 0.6332\n",
            "Epoch 9/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.5558 - accuracy: 0.6513\n",
            "Epoch 9: val_accuracy did not improve from 0.64196\n",
            "104/104 [==============================] - 136s 1s/step - loss: 1.5558 - accuracy: 0.6513 - val_loss: 1.5554 - val_accuracy: 0.6353\n",
            "Epoch 10/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.5292 - accuracy: 0.6532\n",
            "Epoch 10: val_accuracy improved from 0.64196 to 0.64520, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 109s 1s/step - loss: 1.5292 - accuracy: 0.6532 - val_loss: 1.4933 - val_accuracy: 0.6452\n",
            "Epoch 11/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.4953 - accuracy: 0.6565\n",
            "Epoch 11: val_accuracy improved from 0.64520 to 0.64688, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 106s 1s/step - loss: 1.4953 - accuracy: 0.6565 - val_loss: 1.4787 - val_accuracy: 0.6469\n",
            "Epoch 12/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.6595\n",
            "Epoch 12: val_accuracy improved from 0.64688 to 0.65595, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 107s 1s/step - loss: 1.4656 - accuracy: 0.6595 - val_loss: 1.4098 - val_accuracy: 0.6559\n",
            "Epoch 13/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.4237 - accuracy: 0.6647\n",
            "Epoch 13: val_accuracy did not improve from 0.65595\n",
            "104/104 [==============================] - 106s 1s/step - loss: 1.4237 - accuracy: 0.6647 - val_loss: 1.3814 - val_accuracy: 0.6557\n",
            "Epoch 14/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3902 - accuracy: 0.6687\n",
            "Epoch 14: val_accuracy improved from 0.65595 to 0.65694, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 105s 1s/step - loss: 1.3902 - accuracy: 0.6687 - val_loss: 1.3360 - val_accuracy: 0.6569\n",
            "Epoch 15/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3539 - accuracy: 0.6728\n",
            "Epoch 15: val_accuracy improved from 0.65694 to 0.66662, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 108s 1s/step - loss: 1.3539 - accuracy: 0.6728 - val_loss: 1.3040 - val_accuracy: 0.6666\n",
            "Epoch 16/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.3206 - accuracy: 0.6780\n",
            "Epoch 16: val_accuracy improved from 0.66662 to 0.67788, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 107s 1s/step - loss: 1.3206 - accuracy: 0.6780 - val_loss: 1.2597 - val_accuracy: 0.6779\n",
            "Epoch 17/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2822 - accuracy: 0.6819\n",
            "Epoch 17: val_accuracy improved from 0.67788 to 0.68266, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 107s 1s/step - loss: 1.2822 - accuracy: 0.6819 - val_loss: 1.2211 - val_accuracy: 0.6827\n",
            "Epoch 18/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2488 - accuracy: 0.6875\n",
            "Epoch 18: val_accuracy improved from 0.68266 to 0.68542, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 107s 1s/step - loss: 1.2488 - accuracy: 0.6875 - val_loss: 1.2000 - val_accuracy: 0.6854\n",
            "Epoch 19/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.2137 - accuracy: 0.6925\n",
            "Epoch 19: val_accuracy improved from 0.68542 to 0.69021, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 106s 1s/step - loss: 1.2137 - accuracy: 0.6925 - val_loss: 1.1612 - val_accuracy: 0.6902\n",
            "Epoch 20/20\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.1850 - accuracy: 0.6976\n",
            "Epoch 20: val_accuracy improved from 0.69021 to 0.69119, saving model to ./src\\best_model_v1.hdf5\n",
            "104/104 [==============================] - 106s 1s/step - loss: 1.1850 - accuracy: 0.6976 - val_loss: 1.1425 - val_accuracy: 0.6912\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo callback để lưu lại trọng số tốt nhất\n",
        "checkpoint = ModelCheckpoint(\"./src/best_model_v1.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Train model\n",
        "model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history=model.fit(lm_dataset, epochs=20, validation_data=lm_dataset, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Định nghĩa custom objects cho việc load model\n",
        "custom_objects = {'PositionalEmbedding': PositionalEmbedding, 'TransformerDecoder': TransformerDecoder}\n",
        "\n",
        "# Load mô hình từ tệp HDF5\n",
        "with h5py.File(\"./src/best_model_v1.hdf5\", \"r\") as file:\n",
        "    model_from_memory = load_model(file, custom_objects=custom_objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "báo cáo [UNK] [UNK] [UNK] [UNK]\n",
            "báo cáo [UNK] [UNK] [UNK] [UNK]\n",
            "báo cáo [UNK] [UNK] [UNK] [UNK]\n"
          ]
        }
      ],
      "source": [
        "# Tạo một từ điển để ánh xạ từ chỉ mục của từ về từ thực tế\n",
        "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "\n",
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def predict_next_sentence(keyword, max_length, temp=1.0):\n",
        "    input_sentence = keyword\n",
        "    generated_sentence = keyword\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        tokenized_sentence = text_vectorization([input_sentence])\n",
        "        predictions = model_from_memory.predict(tokenized_sentence, verbose=0)\n",
        "        vectorized_prompt = text_vectorization([input_sentence])[0].numpy()\n",
        "        prompt_length = np.nonzero(vectorized_prompt == 0)[0][0]\n",
        "        next_token = sample_next(predictions[0, prompt_length - 1, :], temp)\n",
        "        sampled_token = tokens_index[next_token]\n",
        "\n",
        "        if sampled_token == \"<END>\":\n",
        "            break\n",
        "\n",
        "        generated_sentence += \" \" + sampled_token\n",
        "        input_sentence = generated_sentence\n",
        "\n",
        "    return generated_sentence\n",
        "\n",
        "# Sử dụng hàm để dự đoán câu văn dựa trên từ khóa\n",
        "def detect(keyword):\n",
        "    for _ in range(3):\n",
        "        # keyword = \"báo cáo\"\n",
        "        predicted_sentence = predict_next_sentence(keyword, max_length=4, temp=0.2)\n",
        "        print(predicted_sentence)\n",
        "\n",
        "keyword = \"báo cáo\"\n",
        "detect(keyword)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
